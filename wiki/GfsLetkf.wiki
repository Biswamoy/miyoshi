#summary Documentation for GFS-LETKF

<wiki:toc max_depth="3" />

= Getting started =

== Download our LETKF package ==

Download the latest release version from the [http://code.google.com/p/miyoshi/source/checkout Source tab].

== Prepare required executables and libraries ==

Our LETKF package provides the LETKF assimilation code coupled to the National Centers for Environmental Prediction (NCEP) Global Forecasting System (GFS) model. It requires several executables and libraries from the NCEP, which mainly belong to two NCEP models, GFS and Gridpoint Statistical Interpolation (GSI). Compiling these libraries and models on your computer may not be easy and may take long time.

 * *GFS*: The GFS model is an operational global NWP model developed by the Environmental Modeling Center (EMC) at the NCEP. It is one of the major state-of-the-art operational NWP models over the world and provides main model guidance for the weather forecast in the United States. It is not a community model, and some of the code may not be open to public, so users interested to run the GFS-LETKF system need to contact NCEP to obtain the GFS model code and the associated libraries.
  * NCEP/EMC GFS model page: [http://www.emc.ncep.noaa.gov/index.php?branch=GFS]
  * When you compile the GFS model, you may need to compile the [http://www.earthsystemmodeling.org/ Earth System Modeling Framework (ESMF)] first.

 * *GSI*: The GSI is the primary data assimilation system for the GFS model, based on 3-dimensional variational method (3DVar). In our GFS-LETKF implementation, there is an option to use the GSI as an observation operator. Note that we only use the GSI as the observation operator, and the GSI 3DVar solution is not computed in the GFS-LETKF. Besides, if you are not going to assimilate the satellite radiance data, in the GFS-LETKF package there is also a set of built-in observation operators that does not rely on the GSI. In this case, you do not need to install the GSI.
  * The GSI has been a community model, available at [http://www.dtcenter.org/com-GSI/users/]

=== List of required executables and libraries ===

 * *NCEP executables*:
 After successfully compiling the GFS and GSI, you are asked to put all executable files together in the '{{{$EXECGLOBAL}}}' directory configured in '{{{gfs/run/configure.sh}}}'.
|| *Name* || *Purpose* || *Called from* ||
|| {{{global_fcst}}} || GFS main program || {{{gfs/run/run_gfs.sh}}}<br>{{{gfs/run/cycle.sh}}}<br>{{{gfs/run/fcst.sh}}} ||
|| {{{global_gsi}}} || GSI main program || {{{gfs/run/run_gsi.sh}}}<br>{{{gfs/run/cycle.sh}}} ||
|| {{{global_sighdr}}} || Read the header of the GFS sigma-level input/output files || {{{gfs/run/run_gfs.sh}}}<br>{{{gfs/run/run_gsi.sh}}} ||
|| {{{global_sfchdr}}} || Read the header of the GFS surface input/output files || {{{gfs/run/run_gfs.sh}}}<br>{{{gfs/run/run_gsi.sh}}} ||
|| {{{global_chgres}}} || Change the resolution of the GFS input/output files || {{{gfs/run/run_chgres.sh}}} ||

 * *NCEP libraries required for compiling the GFS-LETKF code*:
 These libraries are required for compiling several programs in the GFS-LETKF package. The path of these libraries are configured in '{{{gfs/configure.user}}}' :
|| *Name* || *Purpose* || *List of files required* || *Link* ||
|| {{{bacio}}} || Basic I/O library for the GFS || {{{$(BACIO_LIB)/libbacio_4.a}}} ||  ||
|| {{{sigio}}} || I/O library for the GFS sigma-level files || {{{$(SIGIO_LIB)/libsigio_4.a}}}<br>{{{$(SIGIO_INC)/sigio_module.mod}}}<br>{{{$(SIGIO_INC)/sigio_r_module.mod}}} ||  ||
|| {{{sfcio}}} || I/O library for the GFS surface-level files || {{{$(SFCIO_LIB)/libsfcio_4.a}}}<br>{{{$(SFCIO_INC)/sfcio_module.mod}}} ||  ||
|| {{{sp}}} || Spectral transform library || {{{$(SP_LIB)/libsp_4.a}}} || [http://www.nco.ncep.noaa.gov/pmb/docs/libs/splib/ncep_splib.shtml] ||
|| {{{bufrlib}}} || I/O library for the BUFR file format || {{{$(BUFR_LIB)/libbufrlib.a}}} || [http://www.nco.ncep.noaa.gov/sib/decoders/BUFRLIB/] ||

 * *Other NCEP libraries that may be required for compiling the GFS and GSI*:
 These libraries may be required when you compile the GFS and GSI, but they are NOT directly required in the GFS-LETKF code.
|| *Name* || *Purpose* ||
|| {{{ip}}} || General interpolation library ||
|| {{{landsfcutil}}} || Land surface library ||
|| {{{gfsio}}} || GFS I/O library ||
|| {{{nemsio}}} || NEMS I/O library ||
|| {{{w3lib}}} || I/O library for the GRIB file format ||

 * *Other required libraries*:
 LAPACK may be required when it is not provided by the Fortran compiler. For example, if you use the Intel Fortran compiler with its Math Kernel Library (MKL), the LAPACK is included and you do not need to install LAPACK by yourself.
|| *Name* || *Purpose* || *Link* ||
|| {{{LAPACK}}} || Linear algebra package || [http://www.netlib.org/lapack/] ||

== Prepare fix files for the GFS and GSI ==

To run the GFS and GSI, they require several "fix" data files (e.g., boundary conditions) and CRTM coefficients. These files need to be put in three directories: '{{{$FIXGLOBAL}}}', '{{{$FIXGSI}}}', and '{{{$FIXCRTM}}}', configured in '{{{gfs/run/configure.sh}}}'.

The GFS fix files can be found at [http://www.nco.ncep.noaa.gov/pmb/codes/nwprod/fix/] , but they are much more than enough to drive a GFS model. It is recommended to select only the necessary files when putting into '{{{$FIXGLOBAL}}}'.

== Test compiling the GFS-LETKF programs ==

When the required libraries are ready, we can do a test compilation of all GFS-LETKF programs.

 * Go to the GFS main directory.
{{{
$ cd gfs
}}}
 * Edit the '{{{configure.user}}}' file, specify the compiler flags and paths of the required libraries in your system. In the '{{{arch}}}' directory, there are a few examples of the '{{{configure.user}}}' file using the PGI or Intel compilers.
 * Compile all GFS-LETKF programs.
{{{
$ make
}}}

=== List of the GFS-LETKF programs ==

If the compilation is successful, you will obtain a number of executable files listed below:
|| *File path and name* || *Purpose* ||
|| {{{common/datetime}}} || A utility for date and time computation ||
|| {{{common/enssize}}} || To simply print the ensemble size ||
|| {{{letkf/efsoXXX}}} || EFSO mean program ||
|| {{{letkf/letkfXXX}}} || LETKF main program ||
|| {{{letkf/meanXXX}}} || To compute the ensemble mean from grid files ||
|| {{{letkf/obsope}}} || Built-in observation operator for non-radiance data ||
|| {{{obs/dec_prcp}}} || To convert the gridded precipitation data to the LETKF observation format ||
|| {{{obs/dec_prepbufr}}} || To convert the NCEP PREPBUFR data to the LETKF observation format ||
|| {{{readdiag_conv}}} || To convert the GSI diagnostic files to the LETKF observation format with model background values ||
|| {{{obs/superob}}} || A superobing/thinning utility ||
|| {{{ssio/grd2ss}}} || To convert a grid file to GFS sig/sfc (spectral) files, and also cycle forecasts into analyses ||
|| {{{ssio/grdctl}}} || To print GrADS ctl files according to the current grid settings ||
|| {{{ssio/ss2grd}}} || To convert GFS sig/sfc (spectral) files to a grid file ||
|| {{{ssio/ss2grdp}}} || To convert GFS sig/sfc (spectral) files to a grid file in pressure coordinates ||
|| {{{ssio/sscycle}}} || To cycle forecasts into analyses ||
|| {{{util/gfsmeanXXX}}} || To compute the ensemble mean from GFS sig/sfc (spectral) files ||
|| {{{verify/verify}}} || A utility to perform verification against observations or other model analyses ||

Note that {{{XXX}}} is the ensemble size that the program is used for.

If some executable files are missing, check the errors and try to fix them.

= Code overview =

== List of scripts ==
All run scripts are located in the "{{{gfs/run}}}" directory, so you will do everything at this directory. The purposes of the scripts are described as follows. Note that for most of the scripts, you can show the usage help by executing them with no arguments.

|| *Script* || *Purpose* ||
|| {{{configure.sh}}} || Main configurations for GFS-LETKF scripts. ||
|| {{{datetime.sh}}} || Date and time functions. ||
|| {{{distribution.sh}}} || Function scripts to adaptively distribute members on nodes. ||
|| {{{stageinout.sh}}} || Function scripts to copy files between the server node and local disks on computing nodes. ||
|| {{{get_ncepobs.sh}}} || Download NCEP conventional observation data from UCAR/DSS. ||
|| {{{get_cfsr.sh}}} || Download NCEP CFSR data. ||
|| {{{run_chgres.sh}}} || Change the resolution of a series of GFS initial conditions. ||
|| {{{mss2grd.sh}}} || Convert GFS sig/sfc files to GrADS grd/grdp files. ||
|| {{{outdir.sh}}} || Create necessary subdirectories and files in the output ({{{$OUTDIR}}}) directory. ||
|| {{{init.sh}}} || Prepare a initial ensemble from a series of analyses at different times. ||
|| {{{init2.sh}}} || Prepare a initial ensemble from outputs of another experiments. ||
|| {{{init3.sh}}} || Prepare a series of initial mean analyses from another source, which is useful to run forecast experiments. ||
|| {{{run_gfs.sh}}} || Prepare a temporary directory for a GFS run, and may run the model. ||
|| {{{run_gsi.sh}}} || Prepare a temporary directory for a GSI run, and may run the model. ||
|| {{{cycle.sh}}} || Run a GFS-LETKF forecast/analysis cycle. ||
|| {{{mcycle.sh}}} || Run multiple cycles. ||
|| {{{fcst.sh}}} || Run (ensemble) forecasts and may also perform forecast verification. ||
|| {{{mfcst.sh}}} || Run multiple-cycle ensemble mean forecasts. ||
|| {{{efsofcst.sh}}} || Run multiple-cycle ensemble forecasts for the EFSO computation. ||
|| {{{verify.sh}}} || Compute verification of ensemble forecasts. ||
|| {{{mverify.sh}}} || Run multiple-cycle verification. ||
|| {{{efso.sh}}} || Compute ensemble forecast sensitivity to observations (EFSO). ||
|| {{{mefso.sh}}} || Run multiple-cycle EFSO. ||
|| {{{pbs_example.sh}}} || An example scripts to submit a parallel job with a jobs scheduling system. ||

== Main configuration script ==

The '{{{configure.sh}}}' is the main configuration file. The other scripts are run based on this configuration file. The explanation of all the configurable variables are provided along with the file (using code comments). Selected variables are explained here:

|| *Variable* || *Description* ||
|| {{{OUTDIR}}} || GFS-LETKF input and output directory. ||
|| {{{SYSNAME}}} || A unique name in the machine, which is used to identify multiple GFS-LETKF runs. ||
|| {{{LTMP1}}}<br>{{{LTMP2}}} || Level 1 and 2 local temporary directories on computing nodes. They are only used when {{{$SHAREDISK = 0}}}. They must exist on all computing nodes. The capacity requirement of the level 1 temporary directory is not too big but the I/O speed is very important; therefore, a RAMdisk ({{{/dev/shm}}} in Linux machines) could be assigned to this variable if the memory on your machine is sufficient. The capacity requirement of the level 2 temporary directory is bigger than {{{$LTMP1}}} and the I/O speed is less important than {{{$LTMP1}}}. The {{{$LTMP1}}} and the {{{$LTMP2}}} can be assigned to the same directory if you do not want to separate the location of different temporary files. ||
|| {{{TMP1}}} || Temporary directory on the server machine. Accessing to this directory from other computing nodes is not required. ||
|| {{{TMPMPI}}} || Temporary directory on the server machine with shared access from all computing nodes. ||
|| {{{SHAREDISK}}} || Do we use local disks on computing nodes to store runtime temporary file?<br>0: Yes, use local disks ({{{$LTMP1}}}, {{{$LTMP2}}}) to store temporary files.<br>1: No, the {{{$OUTDIR}}} is a shared disk that can be accessed from all computing nodes. Use this shared disk to store temporary files.||
|| {{{EXECGLOBAL}}} || Directory of the NCEP executable files (GFS, GSI... etc.). ||
|| {{{FIXGLOBAL}}} || Directory of GFS fix files. ||
|| {{{FIXGSI}}} || Directory of GSI fix files, only required when using GSI as the observation operator ({{{$OBSOPE_OPT = 2}}}). ||
|| {{{FIXCRTM}}} || Directory of CRTM fix files, only required when using GSI as the observation operator ({{{$OBSOPE_OPT = 2}}}). ||
|| {{{ANLGFS}}} || Directory of reference model files in the GFS sig/sfc formats. ||
|| {{{ANLGRD}}} || Directory of reference model files in the sigma-level grid format. ||
|| {{{ANLGRDP}}}<br>{{{ANLGRDP2}}} || Directory of reference model files in the pressure-level grid format. They are used for the verification. The verification results against model data in {{{$ANLGRDP}}} will be stored in '{{{$OUTDIR/verfa1}}}'; the verification results against model data in {{{$ANLGRDP2}}} will be stored in '{{{$OUTDIR/verfa2}}}'. ||
|| {{{INITGFS}}} || Directory of arbitrary initial condition files in the GFS sig/sfc formats. It can be the same as {{{$ANLGFS}}} if the quality of the reference model data in that directory is good. ||
|| {{{OBS}}} || Directory of observation data in the LETKF observation format, required when using the built-in observation operator ({{{$OBSOPE_OPT = 1}}}). ||
|| {{{OBSNCEP}}} || Directory of observation data in the NCEP BUFR format, required when using GSI as the observation operator ({{{$OBSOPE_OPT = 2}}}). ||
|| {{{MEMBER}}} || Ensemble size. It should be the same as the '{{{nbv}}}' variable in '{{{common/common_letkf.f90}}}'. ||
|| {{{MIN_NP_GFS}}}<br>{{{MIN_NP_GSI}}} || Minimum numbers of CPU cores required to run the GFS and GSI. This limit is to avoid using up all available memory per node/core. ||
|| {{{MAX_NP_GFS}}}<br>{{{MAX_NP_GSI}}} || Maximum numbers of cores suggested to run the GFS and GSI. This limit is to avoid poor parallelization efficiency when using too many nodes/cores. ||
|| {{{OBSOPE_OPT}}} || Observation operator options:<br>1: use the LETKF built-in observation operators.<br>2: use the GSI as the observation operator. ||
|| {{{THIN_OPT}}} || Superobing/thinning options:<br>-- Options below (1-2) is for {{{$OBSOPE_OPT = 1}}}<br>1: No superobing/thinning.<br>2: Use superobed/thinned observations processed by the '{{{gfs/obs/superob}}}' program before the LETKF assimilation.<br>-- Options below (3-4) are for {{{$OBSOPE_OPT = 2}}}<br>3: use thinned observations for satellite radiance observations only, processed by the GSI.<br>4: use thinned observations for both conventional and satellite radiance observations, processed by the GSI. ||
|| {{{ADAPTINFL}}} || Adaptive inflation options:<br>0: OFF, no adaptive inflation.<br>1: ON, using inflation parameter 1 cycle ago as the prior.<br>2: ON, using inflation parameter 2 cycles ago as the prior (leap-frog the adaptive inflation fields). ||
|| {{{FCSTLEN}}} || GFS forecast length when running the forecast mode '{{{gfs/run/fcst.sh}}}'. ||
|| {{{OUT_OPT}}}<br>{{{FOUT_OPT}}}<br>{{{OBSOUT_OPT}}}<br>{{{LOG_OPT}}} || How detail do you want to keep for the regular and diagnostic output files in {{{$OUTDIR}}}? See details in the configure script. ||
|| {{{MPIBIN}}} || The path of the '{{{mpiexec}}}' command to run a parallel program. ||
|| {{{BUFRBIN}}} || The path of the '{{{grabbufr}}}' command. ||
== Variables in the source code ==

There are other variables that can not be configured in the '{{{configure.sh}}}', but need to be set in the Fortran source code before compiling the GFS-LETKF programs. After changing the values of these variables, the GFS-LETKF programs need to be re-compiled. Some important variables in the source code are listed and explained below:

|| *Source file* || *Variable* || *Description* ||
|| {{{common/common_letkf.f90}}} || {{{nbv}}} || Ensemble size ||
|| {{{gfs/common/common_gfs.f90}}} || {{{nlon}}}<br>{{{nlat}}} || Longitude and latitude grid numbers of the GFS model. They correspond to the spectral truncation wavenumbers:<br>For T62, {{{$nlon}}} = 192, {{{$nlat}}} = 94<br>For T126, {{{$nlon}}} = 384, {{{$nlat}}} = 190 ||
|| {{{gfs/common/common_gfs.f90}}} || {{{nlev}}} || Number of the vertical levels of the GFS model ||
|| {{{gfs/common/common_gfs.f90}}} || {{{gfs_jcap}}} || Spectral truncation wavenumber of the GFS model ||
|| {{{gfs/common/common_gfs_pres.f90}}} || {{{nlevp}}} || Number of the vertical levels in the GFS-LETKF pressure-level outputs ||
|| {{{gfs/common/common_gfs_pres.f90}}} || {{{levp}}} || List of the vertical levels in the GFS-LETKF pressure-level outputs ||
|| {{{gfs/letkf/letkf_obs.f90}}} || {{{omb_output}}} || Whether output the (observation - background) statistics? ||
|| {{{gfs/letkf/letkf_obs.f90}}} || {{{oma_output}}} || Whether output the (observation - analysis) statistics? ||
|| {{{gfs/letkf/letkf_obs.f90}}} || {{{obsgues_output}}} || Whether output the observation values in the ensemble model background [H(X^b^)]? ||
|| {{{gfs/letkf/letkf_obs.f90}}} || {{{obsanal_output}}} || Whether output the observation values in the ensemble model analyses [H(X^a^)]? This is used for the EFSO computation, and it requires considerable additional computational time of the LETKF main program. ||
|| {{{gfs/letkf/letkf_obs.f90}}} || {{{sigma_obs}}} || Horizontal localization length scale ||
|| {{{gfs/letkf/letkf_obs.f90}}} || {{{sigma_obsv}}} || Vertical localization length scale ||
|| {{{gfs/letkf/letkf_obs.f90}}} || {{{gross_error}}} || Quality control with gross errors ||
|| {{{gfs/letkf/letkf_tools.f90}}} || {{{cov_infl_mul}}} || Multiplicative  covariance inflation parameter:<br>> 0: globally constant inflation<br>< 0: 3D inflation values input from the '{{{infl_mul.grd}}}' file ||
|| {{{gfs/letkf/letkf_tools.f90}}} || {{{sp_infl_mul}}} || Additive covariance inflation parameter ||
|| {{{gfs/letkf/letkf_tools.f90}}} || {{{var_local}}} || Variable localization matrix ||
|| {{{gfs/obs/superob.f90}}} || {{{obmethod_g}}}<br>{{{obmethod_v}}}<br>{{{obmethod_t}}}<br>{{{obmethod_h}}} || Superobing and thinning settings. See details in the code comments. ||
|| {{{gfs/verify/verify.f90}}} || {{{nvrf_obs}}}<br>{{{nvrf_ana}}} || Numbers of the observation datasets and the model analysis datasets used for the verification ||
|| {{{gfs/verify/verify.f90}}} || {{{narea}}}<br>{{{vlon1}}}<br>{{{vlon2}}}<br>{{{vlat1}}}<br>{{{vlat2}}} || Settings of the verification regions ||

== Data formats ==

Below are several data formats appeared in the GFS-LETKF system:

 * *GFS sigma/surface files*
 GFS model inputs and outputs.<br>Abbreviation: *sig/sfc*

 * *GrADS grid files in sigma coordinate (same as the GFS model levels)*
 Gridded files in model levels that can be read by the LETKF main program and plotted with GrADS software.<br>Abbreviation: *grd*

 * *GrADS grid files in pressure coordinate*
 Gridded files in pressure levels, which is defined by '{{{nlevp}}}' and '{{{levp}}}' in '{{{gfs/common/common_gfs_pres.f90}}}'<br>Abbreviation: *grdp*

 * *NCEP PREPBUFR files*
 NCEP PREPBUFR observation date format.<br>Abbreviation: *prepbufr*

 * *LETKF observation format*
 A special observation data format used by the LETKF code.<br>Abbreviation: *letkfobs*

 * *LETKF observation format with model background values*
 Similar to "letkfobs", but with observation values in model backgrounds appended.<br>Abbreviation: *letkfobs2*

 * *GSI diagnostic files*
 The format of the GSI diagnostic outputs<br>Abbreviation: *gsidiag*

== Flow chart ==

[http://miyoshi.googlecode.com/svn/wiki/images/gfs-letkf-flowchart.png]

In the flow chart, the rectangles represent any kind of files with their formats shown in square brackets ([#Data_formats explanation of the data formats and their abbreviations]). Those rectangles are connected by arrow lines that represent program execution, with corresponding program file names shown in the bold italic font next to the arrow lines. Three main components of the system – the data assimilation cycle, the observation processing module, and the model forecast and verification modules – are boxed by the red dashed rectangles. The data assimilation cycle is illustrated in the lower part of the figure: the 9-hour ensemble GFS model integration is executed based on the GFS sigma/surface file formats (sig/sfc), and the LETKF analysis is executed based on the grid file format (grd). The purpose of conducting 9-hour forecasts is to perform a 4-dimensional LETKF (4D-LETKF) which assimilates asynchronous observation data at their right time within a window from hour 3 to hour 9.

The source of the observation data is from the NCEP PREPBUFR dataset that not only provides the observed values but also the observation errors associated with each observation. These observation errors will be used in our system. There are two routes of the observation processing:
 # The route 1 shown in green arrows uses the built-in observation operators that can only process conventional (non-radiance) observation data.
 # The route 2 shown in blue arrows uses the GSI as the observation operator.

A set of reference model analysis data (gray rectangle) is needed in order to provide updated values of some prognostic variables that are not able to be analyzed by the atmospheric data assimilation system, such as ozone concentration and sea surface temperature (SST). It can also be used for the verification.

= Prepare model and observation data =

We need to prepare a set of reference model data in order to update some "boundary conditions" such as SST and ozone concentration during the data assimilation cycle. Therefore, this dataset should cover the entire experiment period. The NCEP has put their Climate Forecast System version 2 Reanalysis (CFSR) [http://nomads.ncdc.noaa.gov/data.php#cfs online] over the period of 1979–2011. They provide the model initial conditions in the GFS sig/sfc format at the [http://nomads.ncdc.noaa.gov/modeldata/cmd_LIC/ T126] and the [http://nomads.ncdc.noaa.gov/modeldata/cmd_HIC/ T382] resolutions. It is convenient to use this dataset as the reference model data for the GFS-LETKF.

There are scripts to download the CFSR (sig/sfc) data, to change the resolution, and to convert them to the gridded data in both model levels (grd) and pressure levels (grdp). In the following demonstration, everything will be run at the T62 resolution, so we are going to download the T126 data and convert them to T62.

== Download the reference model data ==

 * Go to the GFS run directory.
{{{
$ cd gfs/run
}}}
 * Edit the '{{{configure.sh}}}' file. Set '{{{$OUTDIR}}}' to an existing empty directory, and set other variables according to the [#Main_configuration_script variable description]. Pay attention to the '{{{$TMP1}}}', '{{{$EXECGLOBAL}}}', '{{{$FIXGLOBAL}}}', '{{{$ANLGFS}}}', '{{{$ANLGRD}}}', and '{{{$ANLGRDP}}}' variables that will be used in this section. Create empty directories for '{{{$ANLGFS}}}', '{{{$ANLGRD}}}', and '{{{$ANLGRDP}}}'.
{{{
$ mkdir $OUTDIR $ANLGFS $ANLGRD $ANLGRDP
}}}
 * Create a directory to store the T126 CFSR data.
{{{
$ mkdir $CFSR_T126
}}}
 * Use the '{{{get_cfsr.sh}}}' script to download the CFSR data. Note that you can run it without any argument to see the usage help.
{{{
$ ./get_cfsr.sh
}}}
{{{
$ ./get_cfsr.sh 20080101 20080110 $CFSR_T126
}}}
 * Then you will see the CFSR data from January 1 to 10, 2008 will be saved to the '{{{$CFSR_T126}}}' directory following the '{{{YYYYMMDDHH.sig}}}' and '{{{YYYYMMDDHH.sfc}}}' convention.

== Change the resolution of the reference model data ==

 * Create a directory to store the T62 CFSR data.
{{{
$ mkdir $CFSR_T62
}}}
 * Use the '{{{run_chgres.sh}}}' script to change the resolution of the CFSR data from T126 to T62. The '{{{$ANLGFS}}}' below is the variable in '{{{configure.sh}}}'.
{{{
$ ./run_chgres.sh 2008010100 2008011018 62 192 94 $CFSR_T126 $ANLGFS 2
}}}
* Then you will see the CFSR data from January 1 to 10, 2008 are converted to the T62 resolution, saved to the '{{{$ANLGFS}}}' directory.

== Convert the reference model data to gridded data ==

 * Use the '{{{mss2grd.sh}}}' script to convert the T62 CFSR sig/sfc data (in '{{{$ANLGFS}}}' directory) to the gridded data in both model levels and pressure levels (grd/grdp; in '{{{$ANLGRD}}}' and '{{{$ANLGRDP}}}' directories). Pay attention to the '{{{$ANLGFS}}}', '{{{$ANLGRD}}}', and '{{{$ANLGRDP}}}' variables in the '{{{configure.sh}}}' file.
{{{
$ ./mss2grd.sh 2008010100 2008011018
}}}
 * Then you will see the CFSR data from January 1 to 10, 2008 are converted to the gridded data following the '{{{YYYYMMDDHH.grd}}}' convention, saved to the '{{{$ANLGRD}}}' and '{{{$ANLGRDP}}}' directories.
 * You can create GrADS CTL files by the '{{{grdctl}}}' program and use the GrADS software to visualize those data.
{{{
$ ../ssio/grdctl "%y4%m2%d2%h2.grd" "template byteswapped" 00Z01Jan2008 6hr 10000 x > $ANLGRD/yyyymmddhhx.ctl
$ ../ssio/grdctl "%y4%m2%d2%h2.grd" "template byteswapped" 00Z01Jan2008 6hr 10000 p > $ANLGRDP/yyyymmddhhp.ctl
}}}

== Download the GFS initial conditions ==



== Download the NCEP observation data ==

 * Get and compile the '{{{grabbufr}}}' utility that is used to pre-process the NCEP BUFR data. It can be downloaded from [http://ftp.emc.ncep.noaa.gov/gc_wmb/jwoollen/grabbufr/ here]. Please compile it and name the executable file as '{{{grabbufr}}}', put into the '{{{$BUFRBIN}}}' directory set in '{{{configure.sh}}}'.

 * Edit the '{{{configure.sh}}}' file. Pay attention to the '{{{$OBS}}}', '{{{$OBSNCEP}}}', and '{{{$BUFRBIN}}}' variables. Create empty directories for '{{{$OBS}}}' and '{{{$OBSNCEP}}}'.
{{{
$ mkdir $OBS $OBSNCEP
}}}
 * We are going to download the NCEP PREPBUFR data from the [http://rda.ucar.edu/datasets/ds337.0/ CISL Research Data Archive]. You need to register (free) on this website to get an account.
 * Use the '{{{get_ncepobs.sh}}}' script to download the NCEP PREPBUFR data and convert them to the LETKF observation format.
{{{
$ ./get_ncepobs.sh EMAIL PASSWD 20080101 20080110 1
}}}
 * Then you will see the NCEP PREPBUFR data from January 1 to 10, 2008 are saved in the '{{{$OBSNCEP}}}' directory, and they are also converted to the LETKF observation format saved in the '{{{$OBS}}}' directory.

= Run data assimilation cycles =

= Run (ensemble) forecasts and verification =

= Compute EFSO =

Ensemble forecast sensitivity to observations (EFSO)